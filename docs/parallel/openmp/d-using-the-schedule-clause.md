---
title: D. 일정 절
ms.date: 01/22/2019
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: 89e011784c5cccedc4a75f38d553458ea2e5d7e0
ms.sourcegitcommit: 0ab61bc3d2b6cfbd52a16c6ab2b97a8ea1864f12
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 04/23/2019
ms.locfileid: "62362883"
---
# <a name="d-the-schedule-clause"></a>D. 일정 절

병렬 영역 하나 이상의 barrier의 끝에 및 추가적인 장벽을 만들에 있습니다. 각 장벽의에서 팀의 다른 멤버 도착 하는 마지막 스레드가 대기 해야 합니다. 이 대기 시간을 최소화 하려면 공유 작업 해야는 분산 되어 있으므로 모든 스레드가 장애물에 거의 동시에 도착 합니다. 작업에 포함 된 공유는 일부 `for` 구문을 `schedule` 절이이 목적을 위해 사용할 수 있습니다.

동일한 개체에 대 한 일정의 선택에 대 한 참조가 반복 되는 `for` 구문을 주로 메모리 시스템의 현재 상태 및 캐시 및 메모리 액세스 시간 uniform 되는지 크기 등의 특성에 의해 결정 될 수 있습니다 또는 nonuniform 합니다. 이러한 고려 사항을 일부 스레드는 상대적으로 더 적은 작업 중 일부는 루프의 할당 된 경우에 일관 되 게 동일한 집합의 일련의 루프는 배열의 요소를 참조 하는 각 스레드에 만들 수 있습니다. 이 설정을 사용 하 여 수행할 수 있습니다는 `static` 모든 루프에 대 한 동일한 범위를 사용 하 여 일정 합니다. 다음 예제에서는 0으로는 두 번째 루프에서 하한값도 `k` 일정 중요 하지 않은 경우 더 자연 스러운 것입니다.

```cpp
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

나머지 예제에서는 해당 전제 하에 메모리 액세스에는 주요 고려 되지 않습니다. 달리 언급 하지 않으면, 모든 스레드가 비교할 수 있는 계산 리소스를 수신 하 합니다. 이러한 경우에 대 한 일정의 선택에는 `for` 구문을 공유는 모든 작업을 가장 가까운 앞쪽 사이 수행 되어야 하는 것에 따라 달라 집니다 장벽 및 묵시적된 닫는 장애물 또는 다가오는 장애물 없는 경우 가장 가까운는 `nowait` 절입니다. 각 유형의 일정에 대 한 간단한 예제 일정 종류 가장 적합할 가능성이 성은 보여 줍니다. 간단한 설명은 각 예제를 따릅니다.

합니다 `static` 일정은 가장 간단한 경우 하나만 포함 된 병렬 영역에 대 한 적절 한 또한 `for` 각 반복 시 동일한 양의 작업을 사용 하 여 생성 합니다.

```cpp
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

`static` 일정의 특징은 속성을 각 스레드는 거의 같은 수의 반복 다른 스레드로 가져오는 하 고 각 스레드가 하지 결정 독립적으로 수에 할당 되는 반복 합니다. 작업을 배포 하는 동기화가 필요 하므로 및 반복 될 때마다 동일한 양의 작업을 필요는 없다는 가정, 모든 스레드가 완료 되어야에서 동시에 대 한 합니다.

팀의 *p* 스레드 수 *ceiling(n/p)* 는 정수 여야 *q*를 충족 하는 *n = p\*q-r* 를사용하여*0 < = r < p*합니다. 한 가지 구현을 `static` 이 예제에서는 할당에 대 한 예약 *q* 첫 번째 반복 *p-1* 스레드 및 *q r* 는 마지막 스레드가 반복 합니다.  허용 되는 다른 구현을 할당 *q* 첫 번째 반복 *p-r* 스레드 및 *q-1* 나머지 반복 *r*스레드입니다. 이 예제에서는 프로그램의 특정 구현 세부 정보에 의존해 서는 안 되는 이유를 보여 줍니다.

합니다 `dynamic` 일정의 경우에 적합 한를 `for` 다양 한, 또는 예기치 않은 양의 작업을 요구 하는 반복 횟수를 사용 하 여 생성 합니다.

```cpp
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

`dynamic` 일정 보다 더 긴 다른 스레드가 해당 마지막 반복을 실행 하는 스레드가 장애물에 대기 하는 속성으로 규정 됩니다. 이 요구 사항을 반복에 할당 되어야 한 번에 하나씩 각 할당에 대 한 동기화를 사용 하 여 사용 가능 해지면 스레드를 의미 합니다. 최소 청크 크기를 지정 하 여 동기화 오버 헤드를 줄일 수 있습니다 *k* 스레드가 할당 되는 1 보다 큰 *k* 때까지 미만의 *k* 유지 합니다. 스레드가 다른 스레드가 해당 마지막 청크 (최대) 실행 하는 것 보다 더 긴 장애물에 대기 하는 것이 이렇게 *k* 반복 합니다.

`dynamic` 일정 수 계산 리소스를 다양 한 스레드 수신 하는 경우에 유용 하는 효과가 훨씬 같은 다양 한 크기의 각 반복에 대 한 작업으로 합니다. 마찬가지로, 동적 일정 수도 있습니다 스레드 도착 하는 경우에 유용 합니다 `for` 이러한 몇몇 사례에 있지만 다양 한 시간에 생성 합니다 `guided` 일정 더 적합할 수 있습니다.

합니다 `guided` 일정 스레드는 다양 한 시간의 도착할 수 있습니다 하는 경우에 적합 한를 `for` 동일한 양의 작업에 대 한 반복 요구 하 여 생성 합니다. 이 이런 경우에 발생할 수 있습니다, 예를 들어를 `for` 구문 이상의 섹션 앞에 또는 `for` 구문을 `nowait` 절.

```cpp
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

같은 `dynamic`서 `guided` 스레드가 다른 스레드가 해당 마지막 반복을 실행 하는 것 보다 더 길거나 최종 장애물에 대기 하는 보증 예약 *k* 반복 하는 경우의 청크 크기를 *k* 지정 됩니다. 이러한 일정 간에 `guided` 일정의 특징은 속성 가장 적은 동기화 필요 하다는 것입니다. 청크 크기에 대 한 *k*, 일반적인 구현은 할당 *q ceiling(n/p) =* 반복의 첫 번째 사용 가능한 스레드에서 설정 *n* 더 큰 숫자를 *n-q* 하 고 *p\*k*, 모든 반복에 할당 될 때까지 반복 합니다.

최적의 일정의 선택이이 예에 대 한 명확 하 게 없는 경우는 `runtime` 일정 수정 하 고 프로그램을 다시 컴파일하지 않아도 다양 한 일정 및 청크 크기를 사용 하 여 실험 하는 데 유용 합니다. 것도 유용할 수 있습니다 때 프로그램이 적용 되는 입력된 데이터에 대해 최적 일정 (예측 가능한 방식)에 따라 달라 집니다.

서로 다른 일정 간의 장단점의 예제를 보려면, 8 스레드 간에 1000 회 반복을 공유 하는 것이 좋습니다. 각 반복에서 작업의 고정 된 있다고 가정해 보겠습니다를 시간 단위로 사용 합니다.

모든 스레드를 동시에 시작 하는 경우는 `static` 일정에 동기화 되지 않는 125 단위로 실행 하는 구문이 발생 합니다. 하지만 하나의 스레드만 도착 런타임에 100 단위는 가정 합니다. 나머지 7 개의 스레드가 장애물에 100 단위로 기다립니다 및 225로 전체 구문에 대 한 실행 시간이 증가 합니다.

때문에 모두를 `dynamic` 고 `guided` 일정 수 있도록 없습니다 스레드가 장애물에 하나 이상의 장치에 대 한 대기 스레드가 지연된 하면에서 지연 하 여 늘릴 수 있는 138 단위에만 증가 하는 구문에 대 한 각각의 실행 시간 동기화 합니다. 동기화의 수는 1000으로 중요 한 되기 이러한 지연을 무시할 수 없으면 `dynamic` 있지만 대 한 유일한 41 `guided`, 하나의 기본 청크 크기를 가정 합니다. 25, 청크 크기로 `dynamic` 고 `guided` 각각 150 단위와 필요한 동기화에는 이제 수만 40 및 20에서 지연이 마침 둘 다.
