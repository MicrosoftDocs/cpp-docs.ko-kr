---
title: D. Schedule 절 사용
ms.date: 11/04/2016
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: 85386c913a6e447ba9e71231be8b951eef504fea
ms.sourcegitcommit: 6052185696adca270bc9bdbec45a626dd89cdcdd
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 10/31/2018
ms.locfileid: "50627528"
---
# <a name="d-using-the-schedule-clause"></a>D. Schedule 절 사용

병렬 영역 하나 이상의 barrier의 끝에 및 추가적인 장벽을 만들에 있습니다. 각 장벽의에서 팀의 다른 멤버 도착 하는 마지막 스레드가 대기 해야 합니다. 이 대기 시간을 최소화 하려면 공유 작업 해야는 분산 되어 있으므로 모든 스레드가 장애물에 거의 동시에 도착 합니다. 작업에 포함 된 공유는 일부 **에 대 한** 구문을 `schedule` 절이이 목적을 위해 사용할 수 있습니다.

동일한 개체에 대 한 일정의 선택에 대 한 참조가 반복 되는 **에 대 한** 구문을 주로 캐시 및 메모리에 액세스 하는지 여부의 크기와 현재 상태와 같은 메모리 시스템의 특성에 의해 결정 될 수 있습니다 시간에는 uniform 또는 고르지 않은입니다. 이러한 고려 사항을 일부 스레드는 상대적으로 더 적은 작업 중 일부는 루프의 할당 된 경우에 일관 되 게 동일한 집합의 일련의 루프는 배열의 요소를 참조 하는 각 스레드에 만들 수 있습니다. 사용 하 여 이렇게 합니다 **정적** 모든 루프에 대 한 동일한 범위를 사용 하 여 일정 합니다. 다음 예에서는 0으로는 두 번째 루프에서 하한값 하더라도 **k** 일정 중요 하지 않은 경우 더 자연 스러운 것입니다.

```
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

나머지 예제에서는 메모리 가정 액세스의 주요 고려 사항은 아닙니다. 달리 언급 하지 않으면, 모든 스레드가 비교할 수 있는 계산 리소스를 수신 하 고 있습니다. 이러한 경우에 대 한 일정의 선택에는 **에 대 한** 구문을 공유는 모든 작업을 가장 가까운 앞쪽 사이 수행 되어야 하는 것에 따라 달라 집니다 장벽 및 묵시적된 닫는 장애물 또는 후속 장벽, 없는 경우 가장 가까운 `nowait` 절. 각 유형의 일정에 대 한 간단한 예제 일정 종류 가장 적합할 가능성이 성은 보여 줍니다. 간단한 설명은 각 예제를 따릅니다.

합니다 **정적** 일정은 가장 간단한 경우 하나만 포함 된 병렬 영역에 대 한 적절 한도 **에 대 한** 각 반복 시 동일한 양의 작업을 사용 하 여 생성 합니다.

```
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

합니다 **정적** 일정의 특징은 속성을 각 스레드는 거의 같은 수의 반복 다른 스레드로 가져오는 하 고 각 스레드가 하지 결정 독립적으로 수에 할당 되는 반복 합니다. 작업을 배포 하는 동기화가 필요 하므로 및 반복 될 때마다 동일한 양의 작업을 필요는 없다는 가정, 모든 스레드가 완료 되어야에서 동시에 대 한 합니다.

팀의 `p` 스레드 수 *ceiling(n/p)* 는 정수 여야 *q*를 충족 하는 *n = p\*질문 및 답변-r* 사용 하 여 *0 < = r < p* . 한 가지 구현을 합니다 **정적** 이 예제에서는 할당에 대 한 예약 *q* 첫 번째 반복 *p-1* 스레드 및 *q r* 마지막으로 스레드를 반복 합니다.  허용 되는 다른 구현을 할당 *q* 첫 번째 반복 *p-r* 스레드 및 *q-1* 나머지 반복 *r*스레드입니다. 이 프로그램의 특정 구현 세부 정보에 의존 하지 않아야 하는 이유를 보여 줍니다.

합니다 **동적** 일정의 경우에 적합 한를 **에 대 한** 필요한 다양 한, 또는 예측할 수 없는 많은 반복을 사용 하 여 생성 합니다.

```
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

합니다 **동적** 일정 보다 더 긴 다른 스레드가 해당 마지막 반복을 실행 하는 스레드가 장애물에 대기 하는 속성으로 규정 됩니다. 이 반복 할당할 수 있도록 한 번에 하나씩 스레드 각 할당에 대 한 동기화를 사용 하 여 사용 가능 해지면 필요 합니다. 최소 청크 크기를 지정 하 여 동기화 오버 헤드를 줄일 수 있습니다 *k* 스레드가 할당 되는 1 보다 큰 *k* 때까지 미만의 *k* 유지 합니다. 스레드가 다른 스레드가 해당 마지막 청크 (최대) 실행 하는 것 보다 더 긴 장애물에 대기 하는 것이 이렇게 *k* 반복 합니다.

합니다 **동적** 일정 수 계산 리소스를 다양 한 스레드 수신 하는 경우에 유용 하는 효과가 훨씬 같은 다양 한 크기의 각 반복에 대 한 작업으로 합니다. 마찬가지로 동적 일정 수도 있습니다 스레드 도착 하는 경우에 유용 합니다 **에 대 한** 이러한 몇몇 사례에 있지만 다양 한 시간에 생성 합니다 **단계별** 일정 더 적합할 수 있습니다.

합니다 **단계별** 일정 스레드는 다양 한 시간의 도착할 수 있습니다 하는 경우에 적합 한를 **에 대 한** 동일한 양의 작업에 대 한 반복 요구 하 여 생성 합니다. 이 경우에 발생할 수 있습니다, 예를 들어 합니다 **에 대 한** 구문 이상의 섹션 앞에 또는 **에 대 한** 구문을 `nowait` 절.

```
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

와 같은 **동적**의 **단계별** 스레드가 다른 스레드가 해당 마지막 반복을 실행 하는 것 보다 더 길거나 최종 장애물에 대기 하는 보증 예약 *k* 반복 하는 경우 청크 크기인 *k* 지정 됩니다. 이러한 일정 간에 합니다 **단계별** 일정의 특징은 속성 가장 적은 동기화 필요 하다는 것입니다. 청크 크기에 대 한 *k*, 일반적인 구현은 할당 *q ceiling(n/p) =* 반복의 첫 번째 사용 가능한 스레드에서 설정 *n* 더 큰 숫자를 *n-q* 하 고 *p\*k*, 모든 반복에 할당 될 때까지 반복 합니다.

최적의 일정의 선택이이 예에 대 한 명확 하 게 없는 경우는 **런타임** 일정 수정 하 고 프로그램을 다시 컴파일하지 않아도 다양 한 일정 및 청크 크기를 사용 하 여 실험 하는 데 유용 합니다. 것도 유용할 수 있습니다 때 프로그램이 적용 되는 입력된 데이터에 대해 최적 일정 (예측 가능한 방식)에 따라 달라 집니다.

서로 다른 일정 간의 장단점의 예제를 보려면, 1000 회 반복 8 개 스레드 간에 공유 하는 것이 좋습니다. 각 반복에서 작업의 고정 된 있다고 가정해 보겠습니다를 시간 단위로 사용 합니다.

모든 스레드를 동시에 시작 하는 경우는 **정적** 일정에 동기화 되지 않는 125 단위로 실행 하는 구문이 발생 합니다. 하지만 하나의 스레드만 도착 런타임에 100 단위는 가정 합니다. 나머지 7 개의 스레드가 장애물에 100 단위로 기다립니다 및 225로 전체 구문에 대 한 실행 시간이 증가 합니다.

때문에 모두를 **동적** 하 고 **단계별** 일정 없음 스레드가 장애물에 하나 이상의 장치에 대 한 대기를 지연 된 스레드가 하면 138 에게만 늘리려면 구문에 대 한 각각의 실행 시간 확인 단위, 동기화에서 지연 하 여 늘릴 수 있습니다. 동기화의 수는 1000으로 중요 한 되기 이러한 지연을 무시할 수 없는 경우 **동적** 있지만 대 한 유일한 41 **단계별**, 하나의 기본 청크 크기를 가정 합니다. 25, 청크 크기로 **동적** 하 고 **단계별** 각각 150 단위와 필요한 동기화에는 이제 수만 40 및 20에서 지연이 마침 둘 다.