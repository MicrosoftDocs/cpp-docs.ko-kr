---
title: "D. 일정 절을 사용 하 여 | Microsoft Docs"
ms.custom: 
ms.date: 11/04/2016
ms.reviewer: 
ms.suite: 
ms.technology:
- cpp-windows
ms.tgt_pltfrm: 
ms.topic: article
dev_langs:
- C++
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
caps.latest.revision: 
author: mikeblome
ms.author: mblome
manager: ghogen
ms.workload:
- cplusplus
ms.openlocfilehash: b51eeb36a4cffafde0e90586fec08d28b9672e5d
ms.sourcegitcommit: 8fa8fdf0fbb4f57950f1e8f4f9b81b4d39ec7d7a
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 12/21/2017
---
# <a name="d-using-the-schedule-clause"></a>D. 일정 절 사용
병렬 영역의 끝에 하나 이상의 장벽 있으며 추가적인 문제 그 안에 있을 수 있습니다. 각 장벽에는 팀의 다른 멤버 도착 하는 마지막 스레드가 기다려야 합니다. 이 대기 시간을 최소화 하려면 공유 작업을 동시에 대 한 장벽에 도착 하는 모든 스레드가 배포 되어야 합니다. 작업에 포함 되어 있으면 공유 중 일부를 **에 대 한** 구문을 `schedule` 절이 용도로 사용할 수 있습니다.  
  
 동일한 개체에 대 한 일정의 선택에 대 한 반복 된 참조가 있는 경우는 **에 대 한** 구문 확인할 수 있습니다 주로 메모리 시스템의 현재 상태와 크기 캐시 및 메모리에 액세스 하는지 여부 등의 특징 시간은 uniform 또는 고르지 않은 합니다. 이러한 고려 사항을 일부 스레드 중 일부는 루프의 보다 상대적으로 간단 하 게 할당 된 경우에 각 스레드를 일관 되 게 동일한 집합에 일련의 루프로, 배열 요소에 참조를 포함 하는 것이 좋습니다 만들 수 있습니다. 사용 하 여이 작업을 수행할 수 있습니다는 **정적** 동일한 범위의 모든 루프에 대 한 일정입니다. 다음 예제에서 0 하 한으로 두 번째 루프의 경우에 사용 **k** 일정 중요 하지 않은 경우 더 자연 스러운 것입니다.  
  
```  
#pragma omp parallel  
{  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    a[i] = work1(i);  
#pragma omp for schedule(static)  
  for(i=0; i<n; i++)  
    if(i>=k) a[i] += work2(i);  
}  
```  
  
 나머지 예제에서 메모리는 가정 액세스는 주요 고려 언급이 없으면, 모든 스레드가 비교 가능한 계산 리소스를 수신 하 고 있습니다. 이러한 경우에 대 한 일정의 선택에는 **에 대 한** 구문 공유는 모든 작업을 가장 가까운 앞 사이 수행 되어야 하는 것에 의존 방지와 묵시적된 닫는 장벽 또는 후속 장벽, 없는 경우에 가장 가까운 `nowait` 절. 각 종류의 일정에 대 한 간단한 예 일정 이러한 종류는 최상의 선택 일 가능성이 방식을 보여 줍니다. 간략 한 설명은 각 예제를 따릅니다.  
  
 **정적** 일정은 가장 간단한 경우 하나만 포함 된 병렬 영역에 대 한 적절 한 또한 **에 대 한** 동일한 양의 작업을 요구 하는 각 반복을 생성 합니다.  
  
```  
#pragma omp parallel for schedule(static)  
for(i=0; i<n; i++) {  
  invariant_amount_of_work(i);  
}  
```  
  
 **정적** 일정 특징은 속성에 의해 각 스레드가 가져오는 대략 같은 수의 반복 다른 스레드로 하 고 각 스레드가 하지 결정 독립적으로 수에 할당 되는 반복 합니다. 작업을 배포 하는 동기화가 필요 하므로 하 고 각 반복에서 동일한 양의 작업을 필요한 가정 모든 스레드가 완료 되어야에 동시에 대 한 합니다.  
  
 팀에 대 한 `p` 스레드를 통해 *ceiling(n/p)* 는 정수 여야 *q*을 충족 하는 *n = p\*q-r* 와 *0 < r = < p* . 한 가지 구현을 **정적** 이 예제에서는 할당에 대해 예약 *q* 첫 번째 반복 *p-1* 스레드 및 *q r* 마지막 스레드를 반복 합니다.  허용 가능한 다른 구현 할당 *q* 첫 번째 반복 *p-r* 스레드 및 *q-1* 남은 반복 *r*스레드입니다. 프로그램의 특정 구현 세부 정보에 의존 하지 않아야 하는 이유를 설명 합니다.  
  
 **동적** 일정은 대/소문자에 적합 한 **에 대 한** , 다양 한 또는 심지어 예측할 수 없는 많은 작업을 요구 하 고 반복을 생성 합니다.  
  
```  
#pragma omp parallel for schedule(dynamic)  
  for(i=0; i<n; i++) {  
    unpredictable_amount_of_work(i);  
}  
```  
  
 **동적** 일정 보다 더 긴 최종 반복 실행 하는 다른 스레드를 사용에 대 한 장애물에 스레드가 대기 하는 속성의 특징은 합니다. 이 반복을 할당할 수 있도록 한 번에 하나씩 스레드 각 할당에 대 한 동기화 사용 가능 해지면 해야 합니다. 최소 청크 크기를 지정 하 여 동기화 하는 오버 헤드를 줄일 수 있습니다 *k* 스레드 할당 되도록 1 보다 큰 *k* 때까지 미만 *k* 유지 됩니다. 이렇게 하면 다른 스레드에서의 해당 최종 청크 (최대) 실행 하는 것 보다 더 긴 장벽에 스레드가 대기 하는 *k* 반복 합니다.  
  
 **동적** 일정 경우 유용할 수 계산 리소스, 다양 한 스레드 수신 있으며 그 다양 한 크기의 각 반복에 대 한 작업으로 동일한 결과 훨씬 합니다. 마찬가지로, 동적 일정도 유용할 수 있습니다에 스레드가 도달 하는 경우는 **에 대 한** 이 중 일부이 경우에 있지만 다양 한 시간에 생성 된 **단계별** 일정 더 적합할 수 있습니다.  
  
 **단계별** 일정은 스레드 수에 다양 한 시간에 도착 하는 경우에 적합 한 **에 대 한** 동일한 양의 작업에 대 한 각 반복 요구를 생성 합니다. 이 경우 발생할 수 있습니다, 예를 들어는 **에 대 한** 구문 하나 이상의 섹션 앞 또는 **에 대 한** 구문을 `nowait` 절.  
  
```  
#pragma omp parallel  
{  
  #pragma omp sections nowait  
  {  
    // ...  
  }  
  #pragma omp for schedule(guided)  
  for(i=0; i<n; i++) {  
    invariant_amount_of_work(i);  
  }  
}  
```  
  
 마찬가지로 **동적**, **단계별** 스레드가 다른 스레드에서 해당 최종 반복 실행 하는 것 보다 더 길거나 최종 장벽에 대기 하는 보증 예약 *k* 반복 하는 경우의 청크 크기 *k* 지정 됩니다. 이러한 일정 중에서 **단계별** 일정의 특징은 속성 수가 가장 적은 동기화 필요 하다는 것입니다. 청크 크기에 대 한 *k*, 일반적인 구현에서 할당 *q ceiling(n/p) =* 반복이 첫 번째 사용 가능한 스레드를 설정  *n*  더 큰 숫자를 의*n q* 및 *p\*k*, 모든 반복에 할당 된 때까지 반복 합니다.  
  
 최적 일정의 선택이 이러한 예는 달리 명확 하 게 하는 경우는 **런타임** 일정 작업할 수 있도록 각기 다른 일정과 청크 크기를 수정 하 고 프로그램을 다시 컴파일할 필요 없이 편리한 기능입니다. 또한 유용 때 프로그램 적용 되는 입력된 데이터에 최적 일정 (일부 예측 가능한 방식)에 따라 달라 집니다.  
  
 다른 일정 간의 장단점의 예를 보려면 1000 개 루프를 8 개 스레드를 공유 하는 것이 좋습니다. 각 반복에서 작업은 고정 시간 가정할를으로 시간 단위를 사용 합니다.  
  
 모든 스레드는 동시에 시작 하는 경우는 **정적** 일정 동기화 없는 125 장치에서 실행 하는 구문이 발생 합니다. 하지만 스레드를 하나씩 도착 후반부에 100 단위 있다고 가정 합니다. 다음 나머지 7 개 스레드, 장벽에 100 단위 기다린 225에 전체 구문에 대 한 실행 시간이 증가 합니다.  
  
 때문에 모두는 **동적** 및 **단계별** 일정 장벽에 하나 이상의 장치에 대 한 스레드가 대기, 지연 된 스레드 하면 138에만 증가 하는 구문에 대 한 각각의 실행 시간 확인 가능한 동기화에서 지연을 증가 단위입니다. 이러한 지연을 무시할 수 없는 경우 동기화 수는 1000 개로 됩니다 **동적** 있지만 대 한 유일한 41 **단계별**, 하나의 기본 청크 크기를 가정 합니다. 청크 크기의 25, **동적** 및 **단계별** 둘 다 완료 150 단위과만 40, 20, 지금은 번호를 필요한 동기화의 경우에서 간격을 포함 합니다.