---
description: '자세히 알아보기: D. Schedule 절'
title: D. schedule 절
ms.date: 01/22/2019
ms.assetid: bf3d8f51-ea05-4803-bf55-657c12e91efe
ms.openlocfilehash: bd1bb4f9a6c661205e2e647fc9e45d81903008c8
ms.sourcegitcommit: d6af41e42699628c3e2e6063ec7b03931a49a098
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 12/11/2020
ms.locfileid: "97342493"
---
# <a name="d-the-schedule-clause"></a>D. schedule 절

병렬 영역의 끝에는 하나 이상의 장벽이 있으며 그 안에 추가 장벽이 있을 수 있습니다. 각 장벽에서 팀의 다른 멤버는 마지막 스레드가 도착할 때까지 기다려야 합니다. 이 대기 시간을 최소화 하기 위해 공유 작업을 분산 하 여 모든 스레드가 동시에 장벽에 도달 하도록 해야 합니다. 이러한 공유 작업 중 일부가 구문에 포함 된 경우 `for` 절을 `schedule` 이 용도로 사용할 수 있습니다.

동일한 개체에 대 한 반복 참조가 있는 경우에는 `for` 캐시의 현재 상태와 크기 및 메모리 액세스 시간이 균일 한지에 관계 없이 메모리 시스템의 특성에 따라 구문에 대 한 일정을 선택할 수 있습니다. 이러한 고려 사항은 일부 스레드가 일부 루프에서 상대적으로 적은 작업을 할당 하는 경우에도 각 스레드가 일련의 루프에서 배열의 동일한 요소 집합을 일관 되 게 참조 하 게 하는 것이 좋을 수 있습니다. 이 설정은 `static` 모든 루프에 대해 동일한 범위의 일정을 사용 하 여 수행할 수 있습니다. 다음 예에서는 `k` 일정이 중요 하지 않은 경우에도 0이 두 번째 루프에서 하한값으로 사용 됩니다.

```cpp
#pragma omp parallel
{
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    a[i] = work1(i);
#pragma omp for schedule(static)
  for(i=0; i<n; i++)
    if(i>=k) a[i] += work2(i);
}
```

나머지 예제에서는 메모리 액세스를 기준으로 고려 하지 않는다고 가정 합니다. 별도로 언급 하지 않는 한 모든 스레드는 비슷한 계산 리소스를 수신 합니다. 이러한 경우, 구문에 대 한 일정을 선택 하는 것은 절이 있는 `for` 경우 가장 가까운 것과 가장 가까운 장애물 사이에서 수행 해야 하는 모든 공유 작업에 따라 결정 됩니다 `nowait` . 각 일정 종류에 대해 간단한 예제에서는 일정 종류를 선택 하는 것이 가장 좋은 방법을 보여 줍니다. 각 예제에 대 한 간략 한 설명은 다음과 같습니다.

`static`이 일정은 가장 간단한 사례, 단일 구문을 포함 하는 병렬 영역 `for` , 각 반복이 동일한 양의 작업을 필요로 하는 경우에도 적합 합니다.

```cpp
#pragma omp parallel for schedule(static)
for(i=0; i<n; i++) {
  invariant_amount_of_work(i);
}
```

`static`일정은 각 스레드가 다른 스레드와 거의 동일한 수의 반복을 가져오는 속성으로 구분 되며, 각 스레드는 자신에 게 할당 된 반복을 독립적으로 확인할 수 있습니다. 따라서 작업을 배포 하는 데 동기화가 필요 하지 않으며 각 반복에 동일한 양의 작업이 필요 하다 고 가정 하에 모든 스레드가 동시에 완료 되어야 합니다.

*P* 스레드 팀의 경우 최대 *(n/p)* 는 *n = p \* q-r* 을 만족 하는 정수 *q* 로, *0 <= r < p* 를 사용 합니다. 이 예의 일정을 한 번 구현 하면 `static` 첫 번째 *p-1* 스레드에 *q* 반복을 할당 하 고 마지막 스레드에 *q-r* 반복을 할당 합니다.  사용할 수 있는 또 다른 구현은 *q* 반복을 첫 번째 *p-r* 스레드에 할당 하 고 나머지 *r* 스레드에는 *q-1* 회 반복을 할당 합니다. 이 예제에서는 프로그램이 특정 구현에 대 한 세부 정보를 사용 하지 않아야 하는 이유를 보여 줍니다.

`dynamic`일정은 다양 하거나 예측할 수 없는 작업을 필요로 하는 반복을 포함 하는 구문의 경우에 적합 합니다 `for` .

```cpp
#pragma omp parallel for schedule(dynamic)
  for(i=0; i<n; i++) {
    unpredictable_amount_of_work(i);
}
```

`dynamic`일정은 다른 스레드를 사용 하 여 최종 반복을 실행 하는 것 보다 오랜 시간 동안 스레드가 대기 하지 않는 속성에 의해 구분 됩니다. 이 요구 사항은 각 할당에 대 한 동기화를 사용 하 여 스레드를 사용할 수 있게 되 면 한 번에 하나씩 반복을 할당 해야 함을 의미 합니다. 1 *보다 큰 최소 청크 크기인 k를* 지정 하 여 동기화 오버 헤드를 줄일 수 있습니다. 그러면 *k* 개 미만으로 유지 될 때까지 스레드에 *k* 가 할당 됩니다. 이렇게 하면 스레드가 다른 스레드를 사용 하 여 최대 *k* 회 반복의 최종 청크를 실행 하는 것 보다 오래 대기 하 게 됩니다.

`dynamic`각 반복에 대해 다양 한 작업을 수행 하는 것과 거의 동일한 효과를 가진 다양 한 계산 리소스를 스레드에서 받는 경우에는 일정이 유용할 수 있습니다. 이와 마찬가지로 동적 일정은 스레드가 다양 한 시간에 생성 될 경우에도 유용할 수 있습니다 `for` . 그러나 이러한 경우에는 일정을 사용할 수 있습니다 `guided` .

`guided`일정은 `for` 각 반복이 동일한 양의 작업을 필요로 하는 구문에서 다양 한 시간에 스레드가 도착할 수 있는 경우에 적합 합니다. 예를 들어 `for` 구문 앞에 절이 있는 하나 이상의 섹션 또는 구문이 있는 경우 이러한 상황이 발생할 수 있습니다 `for` `nowait` .

```cpp
#pragma omp parallel
{
  #pragma omp sections nowait
  {
    // ...
  }
  #pragma omp for schedule(guided)
  for(i=0; i<n; i++) {
    invariant_amount_of_work(i);
  }
}
```

이와 같이 `dynamic` `guided` 일정은 다른 스레드가 최종 반복을 실행 하는 데 걸리는 시간 보다 오래 기다리거나, 청크 크기가 *k* 가 지정 된 경우 최종 *k* 회 반복이 발생 하지 않도록 보장 합니다. 이러한 일정 중에서 일정은 가장 `guided` 적은 동기화를 필요로 하는 속성으로 규정 됩니다. 청크 크기 *k* 의 경우 일반적인 구현에서는 *q = 상한 (n/p)* 반복을 첫 번째 사용 가능한 스레드에 할당 하 고 *n* 을 *n-q* 및 *p \* k* 의 큰 값으로 설정 하 고 모든 반복이 할당 될 때까지 반복 합니다.

최적 일정의 선택이 이러한 예제에 대 한 것 처럼 명확 하지 않은 경우에는 `runtime` 프로그램을 수정 하 고 다시 컴파일하지 않고도 일정 및 청크 크기를 시험해 볼 수 있습니다. 또한 최적의 일정이 프로그램이 적용 되는 입력 데이터에 종속 된 경우 (예측 가능한 방식으로) 유용할 수 있습니다.

서로 다른 일정 간의 장단점에 대 한 예를 보려면 8 개 스레드 간에 1000 반복을 공유 하는 것이 좋습니다. 각 반복에 고정 된 양의 작업이 있고이를 시간 단위로 사용 한다고 가정 합니다.

모든 스레드가 동시에 시작 되는 경우 일정을 `static` 사용 하면 동기화가 없는 125 단위로 구문이 실행 됩니다. 그러나 한 스레드의 경우에는 100 단위를 지연 하는 것으로 가정 합니다. 그런 다음 남은 7 개 스레드가 장벽에서 100 단위를 대기 하 고 전체 구문의 실행 시간이 225으로 늘어납니다.

`dynamic`및 `guided` 일정 모두 장벽에서 두 개 이상의 단위를 대기 하지 않도록 하기 때문에 지연 된 스레드는 구성에 대 한 실행 시간을 138 단위 까지만 늘리기 때문에 동기화의 지연으로 인해 증가할 수 있습니다. 이러한 지연 시간이 무시 되지 않는 경우에는 동기화의 수가 1000에 대해 `dynamic` 41 이지만의 `guided` 기본 청크 크기가 1 인 것으로 가정 하는 것이 중요 합니다. 청크 크기가 25이 `dynamic` 고 `guided` 둘 다 150 단위로 완료 되며, 필요한 동기화의 지연 (이제는 각각 40 및 20)을 더한 값입니다.
